{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing libraries  for visualisation of data\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "\n",
    "#Importing sklearn libraries for modelling and evaluation\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor as knnr\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "\n",
    "\n",
    "from random import randint #To generate random numbers in a given range\n",
    "\n",
    "#Importing datetime module\n",
    "from time import time\n",
    "from datetime import date, timedelta #For creating additional time based features\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler ## Importing the MinMax Scaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, roc_curve, roc_auc_score, auc, mean_squared_log_error\n",
    "\n",
    "\n",
    "#importing all the important libraries\n",
    "#Importing XGBoost module\n",
    "import xgboost as xgb \n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBRegressor #For modelling train data to predict Sales\n",
    "\n",
    "pd.set_option('display.max_columns', None)  #To display all the columns in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppf = pd.read_csv('processedflights15july.csv')\n",
    "\n",
    "# X = ppf.drop([\"Arrival Delay (Minutes)\", \"Delayed?\",\"Taxi-In time (Minutes)\", \"xa\", \"ya\", \"Departure Delay (Minutes)\"],axis=1)\n",
    "X = ppf.drop([\"Arrival Delay (Minutes)\", \"Delayed?\"],axis=1)\n",
    "y = ppf[\"Arrival Delay (Minutes)\"]\n",
    "y1 = ppf[\"Delayed?\"]\n",
    "y2 = ppf[\"Departure Delay (Minutes)\"]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "\n",
    "train_x,test_x,train_y,test_y = train_test_split(Xs,y1, test_size=0.2, random_state = 50, stratify=y1)\n",
    "#for classification\n",
    "train_x1, val_x, train_y1, val_y = train_test_split(train_x, train_y, test_size = 0.2 , random_state = 50, stratify = train_y)\n",
    "\n",
    "print('training data    ',train_x.shape,train_y.shape)\n",
    "print('validation data  ',val_x.shape,val_y.shape)\n",
    "print('test data        ',test_x.shape,test_y.shape)\n",
    "\n",
    "train_xr,test_xr,train_yr,test_yr = train_test_split(Xs,y, test_size=0.2, random_state = 50, stratify=y1)\n",
    "#for arrival regression\n",
    "train_x1r, val_xr, train_y1r, val_yr = train_test_split(train_xr, train_yr, test_size = 0.2 , random_state = 50, stratify = train_y)\n",
    "\n",
    "print('training data    ',train_xr.shape,train_yr.shape)\n",
    "print('validation data  ',val_xr.shape,val_yr.shape)\n",
    "print('test data        ',test_xr.shape,test_yr.shape)\n",
    "\n",
    "train_xr1,test_xr1,train_yr1,test_yr1 = train_test_split(Xs,y2, test_size=0.2, random_state = 50, stratify=y1)\n",
    "#for delay regression\n",
    "train_x1r1, val_xr1, train_y1r1, val_yr1 = train_test_split(train_xr1, train_yr1, test_size = 0.2 , random_state = 50, stratify = train_y)\n",
    "\n",
    "print('training data    ',train_xr1.shape,train_yr1.shape)\n",
    "print('validation data  ',val_xr1.shape,val_yr1.shape)\n",
    "print('test data        ',test_xr1.shape,test_yr1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params0 = {\"objective\": \"reg:linear\",          \n",
    "        \"booster\" : \"gbtree\",\n",
    "          \"eta\": 0.05,\n",
    "          \"max_depth\": 12,\n",
    "          \"subsample\": 0.95,\n",
    "          \"colsample_bytree\": 0.9,\n",
    "          \"silent\": 1,\n",
    "          \"seed\": 50}\n",
    "\n",
    "#   \n",
    "num_round0 = 600\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(train_xr, train_yr)\n",
    "dvalid = xgb.DMatrix(test_xr, test_yr)\n",
    "# We will assign the \"evals\" parameter the value watchlist which is a requirement for early_stopping_rounds\n",
    "evals0 = [(dtrain, 'train'), (dvalid, 'val')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbmodel = xgb.train(params0, dtrain, num_round0, evals=evals0, early_stopping_rounds=30, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds = xgbmodel.predict(xgb.DMatrix(test_xr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ypreds[:5])\n",
    "print(test_yr[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.sqrt(mse(test_yr, ypreds))\n",
    "error"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
